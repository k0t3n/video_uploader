# Выводы

Я посчитал необходимым написать сопроводительное письмо с парой дисклеймеров к
решению [тестового задания](https://docs.google.com/document/d/13uXcDHhmi_4psNHFZX5x-uJ8V8dOunKHjuVriPZKPqI).

## Декодирование

### Обзор решений

Так как в рамках задания была дана условная свобода действий, то декодировать обычным ffmpeg показалось мне не самым
гибким решением. Если рассматривать проект с точки зрения MVP, где основными являются быстрота и функционал, то
разработка велосипедов на этом этапе было бы ошибкой. Варианты которые я рассматривал:

| Solution | + | - |
| :-------------: |:-------------:|:-----:|
| FFmpeg   | условно бесплатно, полностью подконтрольно | Разработка полного цикла, поддержка инфраструктуры, ручное конфигурирование, небезопасно (постоянно находят дырки) |
| AWS Lambda + FFmpeg | Низкая цена, автоскейлинг | Ограниченное время работы скрипта (15 минут), костыль (будем честны) |
| AWS Elastic Transcoder | Работает из коробки, интеграция с S3, большое количество поддерживаемых форматов, | Legacy service (AWS просит переходить на MediaConvert)|
| AWS MediaConvert | Быстрая конфигурация, интеграция с S3, огромное количество поддерживаемых форматов и кодеков, автоскейлинг, надежность (SLA 99.9%) | Vendor lock, цена |

Учитывая, что декодинг минутного ролика в формате HD на AWS MediaConvert будет стоить примерно 0.05$, а работы
разработчика по интеграции подобного функционала на FFmpeg оценим в 1500$, то решение окупится при декодинге **~42 часов
видео ежемесячно** в течение года (**БЕЗ** учета инфраструктурных расходов).

### Кодеки

В задании не было четких требований по кодекам, поэтому я посмотрел
на [таблицу совместимости браузеров](https://www.encoding.com/html5-video-codec/) и выбрал **VP8** для **WebM** и
**H.264** для **MP4** как наиболее популярные и поддерживаемые. Прочитал несколько классных статей от Netflix по их
экспериментам с кодеками и разрешениям для различных девайсов (до этого я с видео никак не работал). Не rocker science,
но тоже очень нетривиально!

## Как это работает

1. Со страницы создания видео на бекенд попадает файл или ссылка. Максимальный размер загружаемого файла конфигурируется
2. После создания записи в БД срабатывает сигнал на фоновое создание задачи в AWS, статус видео изменяется на `encoding`
   или `error` в случае внезапной ошибки.
3. Воркер автоматически запрашивает обновления по всем видео в статусе `encoding` каждые 30 секунд используя блокирующие
   вызовы к БД. Это исключает состояние гонки и обеспечивает консистентность данных.
4. В случае успешного завершения задачи в модели `EncodedVideos` создаются записи с новыми файлами, в родительскую
   модель добавляется превью, а статус видео меняется на `succeeded`.

## Но можно и лучше

## Отдельные задачи

Создание превью и декодинг видео в каждом формате/кодеке по-отдельности можно разбить на отдельные задачи в AWS - это
позволит доставлять готовые файлы быстрее. Сейчас это происходит в одной задаче.

### AWS Hooks

Присылаются на любые события с job. Подобные колбеки позволят оптимизировать работу воркеров, которые в текущем варианте
ходят за обновлениями сами раз в 30 секунд.

### Тесты

Их нужно писать и писать много. Здесь я физически не успел написать ни одного тест-кейса.

### CI

При выполнении этого задания открыл для себя Github Actions - это очень замечательная штука, которая уже обгоняет Gilab
CI по удобству и возможностям. Тем не менее все мои основные паттерны и конфиги были написаны для Gitlab, поэтому
перенести их в короткие сроки не получилось. Что там должно было быть:

* Оптимизированный docker build с кешами
* Django checks (это `manage.py check` и падающий `makemigrations --dry-run` при неконсистентности моделей и миграций.
  На реальных проектах этот стейдж показывает очень большую эффективность в плане проверки банальных ошибок
  разработчиков.
* Запуск тестов (само собой)

### Helm secrets

Над секретами нужно поработать - сейчас они будут храниться в открытом виде в etcd. Кажется, самым удачным вариантом
будет использовать Vault.

### БД не в k8s

Очень холливарная тема. Но из того опыта что у меня есть - БД не стоит тянуть в продовский кластер если в этом нет явной
необходимости и достаточной экспертизы. Для этого лучше использовать облачные решения. Поэтому в задании нет PV для
базы.

### Ресурсы
Стоит ограничивать использование CPU/RAM подами в боевых конфигурациях.

### Healthchecks

В текущем варианте бекенд проверяет только подключение к БД. Должен ко всем остальным сервисам.

### Адекватный фронтенд

Чувствую, что уже пора применять реактивные фреймворки и смотреть в сторону fullstack. То что сейчас в шаблоне - немного
ужас, но вы обещали не ругать :)

### Пакетный менеджер

Poetry кажется очень интересным, но времени на эксперименты совсем не было (а хотелось). Поэтому здесь
стандартный `requirements.txt`.

